<template><div><p>（一）大数据基础（与云原生合并） 预计3到4个小时<br>
1. 大数据的起源与发展历程 （主要介绍大数据诞生的原因以及后续的简要发展历史）<br>
2. 分布式存储与分布式计算原理（不涉及具体计算框架，只讲通用的原理，方面后面介绍其他技术的时候做铺垫，也为后面的测试方案打基础）<br>
3. 大数据的生态介绍（基于上面的分布式计算和存储的原理，展开各自都发展出了什么样的生态，重点要介绍清楚什么样的场景用什么样的技术，比如基础存储是hdfs，但大批量离线分析OLAP用hive，实时性更高的查询分析用impala。需要解释清楚各自的优势和使用场景）<br>
a. 存储方向：<br>
i. HDFS -- 介绍HDFS架构和存储原理。<br>
ii.Kudu -- 一种同时支持支持随机读写和顺序读写的解决方案， 是HDFS和HBASE的折中方案。 这里要解释清楚HDFS, Kudu, HBASE下的常用业务架构。<br>
iii.hudi -- 一种较为流行的数据湖的技术选型，支持增量查询与upsert能力。 这里第一次初步引出数据仓库与数据湖的概念，解释清楚他们各自的使用场景。这里也可以引出hive的存储为什么不适合很多场景的原因 。<br>
iiii. ceph -- 一种越来越流行的基于对象存储的分布式存储软件，在云原生时代尤其受欢迎， 更适合存储较小的数据。  这里也引出对象存储，文件存储和块存储的区别。<br>
b. 计算方向:<br>
i. MapReduce -- 简单介绍即可， 毕竟现在基本没人用了<br>
ii. Spark -- 批处理最流行的计算框架，重点介绍内容：rdd，partition，shuffle与数据倾斜，spark计算的原理。根据这些内容在这里第一次引出部分测试场景但不会详细展开。<br>
iii. flink -- 流计算领域的王者，在这里主要介绍使用场景， 具体的详细内容和测试在后续讲解。<br>
iiii. hive -- 数据仓库常用的数据选型， 对比spark sql，专门优化了查询性能。<br>
iiiii. impala -- hive适合大数据量的批量分析场景，而impala则在小数据量下的实时查询领域表现更好<br>
c. 集群方向（资源调度）<br>
i. hadoop（yarn）--传统的资源调度集群，支持vcore和memory的资源调度，支持多个queue之间的租户隔离。<br>
ii. MPP（大规模并行处理集群） -- 以impala为例子简单介绍一下它的特点<br>
ii.K8S -- 云原生时代的首选调度框架。因为云原生的内容太多了， 这里只介绍核心 内容：<br>
a.  什么是云原生， 云原生与传统模式的主要区别（主要介绍容器和声明式API）<br>
b.  K8S的资源调度策略，包括（request和limit，驱逐策略，资源优先级和抢占优先级, 异构资源的调度--Device plugin）<br>
c.  K8S中的存储策略-- pv与pvc，各个分布式存储与k8s集成的形态，如何通过pv和pvc管理权限，用量等<br>
d.  边缘计算与存储-- 简单介绍一下这种场景下的存储形态，不会特别深入讲解。<br>
第一部分重要的地方：</p>
<ol>
<li>要讲解明白每种大数据软件的使用场景，他们之间的关系。 比如在hadoop生态里，hdfs是最基础的存储软件， 但它由于自身特点在一些垂直领域有所不足。 所以在hdfs+spark的基础上为了优化大规模查询分析（OLAP）所以扩展出了hive（hive也成为了最常用的数据仓库技术选型），而hive在大规模的查询分析上具有优势，但准实时能力较差，所以在hive的基础上又开发出了impala。 又比如hdfs在顺序读取上表现比较好，但无法支持随机读取。 而HBAS在随机读取支持的很好但又不支持顺序读取，所以kudu作为一个这种方案被开发出来。  所以在第一部分 要讲明白每一种技术选型的使用 场景和优势，它们又是如何在真实场景中配合共同支撑业务的。</li>
<li>集群调度领域要讲明白hadoop和k8s各自的原理， 各自的优势，尤其要讲明白大数据与云原生集成的形态。</li>
<li>要先简单介绍整体大数据生态下的常用数据治理方案。比如数据仓库和数据湖的基本概念， 它们各自要支撑什么样的业务场景。 让大家对整个大数据生态下的数据架构有个基本的了解。</li>
</ol>
<p>（二）离线批处理背景下的测试场景 --预计2个小时</p>
<ol>
<li>以Spark为例讲解分布式计算中批处理的计算原理（其他计算框架也是类似的， 尽量抛离spark本身的特性，专注讲解所有计算框架都要面对的问题）<br>
a. rdd简介， 并且简单介绍各个算子的作用。<br>
b. spark sql和dataframe简介（就是简单介绍）<br>
c. 数据分区（partition）与spark的计算流程</li>
<li>性能测试场景详解：<br>
a. 性能测试场景：<br>
i. shuffle和数据倾斜的详解。 为何数据倾斜是所有分布式计算的性能杀手<br>
ii 数据分区和计算性能的关系。为何海量小文件是所有分布式计算和分布式存储的性能杀手<br>
iii. 数据导入测试场景下的难点。<br>
b. 造数平台的建设（大数据的性能测试需要模拟各种不同的数据），主要以结构化数据主要以spark + k8s/hadoop + datax作为开发手段，海量小文件场景主要以异步IO+k8s完成，计算机视觉领域中常用的视频流模拟主要用easydarwin+ ffmpeg来模拟。 PS（都有代码demo提供）<br>
i. 模拟不同数据规模（行数，列数）<br>
ii. 模拟不同数据分布（模拟数据倾斜）<br>
iii.模拟不同数据格式（行存储，列存储等）<br>
iii.模拟不同的数据源（主要在数据导入测试中使用）<br>
iiii. 模拟海量的小文件(主要利用异步io+k8s来完成)<br>
iiiii. 模拟大量视频流（easydarwin+ ffmpeg），这里稍微扩展说明一下人工智能业务中，计算机视觉方向的业务和测试<br>
c. 数据质量监控（技术实现比较简单，主要以大数据技术制定业务规则，扫描数据来进行验证），主要讲解都需要验证哪些点。<br>
d. 单元测试简介（主要介绍udf和udaf的场景）<br>
第二部分重点：</li>
<li>着重分布式计算原理的细节， 需要讲清楚运行机制，数据分区，数据倾斜，shuffle等对性能的影响。结合第一部分讲解各自的存储和计算框架的性能表现。 尤其是要结合spark的机制来说明每种场景下应该注意哪些性能点。</li>
<li>造数平台的建设思路，编码演示，每种场景应该对应哪种造数工具都需要详细说明。 并讲解性能测试场景下不同目的需要创建什么样的数据</li>
</ol>
<p>（三）流计算背景下的测试场景 --预计2个小时</p>
<ol>
<li>以Flink为例讲解分布式计算流计算的计算原理。<br>
a. 首先介绍常见的业务场景，以kafka+flink为例<br>
b. flink中窗口的概念（数量窗口和时间窗口，滚动窗口和时间 窗口）<br>
c. flink中的时间概念（event time，process time， ingestor time）以及watermark的原理（涉及到造数的细节）<br>
d. flink中的check point和state backend<br>
e. flink中的反压原理，反压会给checkpoint造成什么影响（这里会引出性能测试中需要关注的点）</li>
<li>以Kafka为例进一步说明流计算场景<br>
a. producer，broker，consumer简介<br>
b. partiton与topic简介， partition与consumer group的关系，重平衡的影响（这里要引出性能测试中需要关注的点）<br>
c. 数据一致性测试：kafka的一次性语义（精准一次性，至多一次性，至少一次性）， 幂等producer，分布式事务producer<br>
d. 数据一致性测试：flink中的精准一次性语义，以及checkpoint机制带来的数据重复问题。</li>
<li>流计算中的单元测试（udf，拆流测试）<br>
第三部分重点：<br>
流计算的完整架构和其中重要的跟性能和数据一致性相关的内容， 因为在实际场景中这部分最容易出现问题。 要从flink和kafka的原理分析各种会出现性能瓶颈和数据不一致的场景并针对性设计测试用例。</li>
</ol>
<p>（四）案例介绍 -- 营销系统（预计1个小时）</p>
<ol>
<li>简单介绍营销系统的业务逻辑，预计5~10分钟。</li>
<li>重点介绍技术架构，尤其介绍流计算和批处理在这里面起到的作用。</li>
<li>介绍性能测试场景和测试工具（由于很多测试场景在上面介绍流计算和批处理的时候就介绍过了，所以就不会特别详细的讲了）<br>
a. 查询分析场景下，常见的几种容量测试的方法（MPP，k8s和yarn的方法有些许的不一样）。（主要利用造数工具进行容量测试）<br>
iii. 如果有时间，需要介绍一下在K8S下做容量测试所需要开发的工具（普罗米修斯+自研监控）<br>
b. 如何利用kafka来开发大并发下的mock服务。</li>
<li>数据一致性测试（在流计算中已经比较详细的讲解了， 所以这里只是简单介绍）<br>
（五）案例介绍-- 人工智能平台（预计1小时）</li>
<li>介绍人工智能平台的业务逻辑（不是专题讲AI，所以仅仅简单介绍）<br>
a. 数据导入模块（批处理，流计算，预处理ETL，类型自动识别）<br>
b. ETL, 特征提取等批处理逻辑<br>
c. 模型上线后的流计算处理和自学习</li>
<li>线上线下一致性测试</li>
<li>数据治理测试（简单介绍）<br>
a. 数据血缘与追溯<br>
b. 数据清理，TTL，租户隔离等</li>
<li>基于统计的测试方法（以评估模型效果的案例说明）</li>
</ol>
<p>第四第五部分重点：<br>
这两部分主要是案例介绍，  用两个实际的案例来说明大数据技术是如何支撑产品业务的， 尤其是流计算和批处理相互配合的场景需要说清楚。 同事也要说明白不用的技术选型是为了什么目的。</p>
</div></template>


